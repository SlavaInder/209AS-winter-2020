{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improts and setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup envirnonment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessaary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import tempfile\n",
    "from urllib.request import urlretrieve\n",
    "import tarfile\n",
    "import json\n",
    "import imp\n",
    "import os\n",
    "\n",
    "import IPython.display as display\n",
    "import PIL.Image\n",
    "\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import custom libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import patch_utils\n",
    "import image_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'image_utils' from '/home/slavchic/Desktop/209AS_winter_2020/python_files/image_utils/__init__.py'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp.reload(patch_utils)\n",
    "imp.reload(image_utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_json, _ = urlretrieve(\n",
    "    'http://www.anishathalye.com/media/2017/07/25/imagenet.json')\n",
    "with open(imagenet_json) as f:\n",
    "    imagenet_labels = json.load(f)### Choose an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify training set\n",
    "number_of_images = 5\n",
    "my_classes = ['cat', 'ship']\n",
    "my_valid_range = (0, 10)\n",
    "\n",
    "\n",
    "# specify the patch size, mean, std\n",
    "mean = 0\n",
    "std = 0.3\n",
    "size = 50\n",
    "\n",
    "# get train images \n",
    "train_set = image_utils.sample_images(my_classes, number_of_images, valid_range = my_valid_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patch setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch creator\n",
    "class patch_multiplier(layers.Layer):\n",
    "    \n",
    "    def __init__(self, patch_size=50, patch_mean=0, patch_std=0.3):\n",
    "        super(patch_multiplier, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.patch_mean = patch_mean\n",
    "        self.patch_std = patch_std\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.patch = self.add_weight(shape=(self.patch_size, self.patch_size, 3),\n",
    "                                     initializer=tf.random_normal_initializer(mean=self.patch_mean, \n",
    "                                                                              stddev=self.patch_std, \n",
    "                                                                              seed=None),\n",
    "                                     trainable=True,\n",
    "                                     name='patch')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        multiple_patches = tf.broadcast_to(self.patch, (tf.shape(inputs)[0], self.patch_size, self.patch_size, 3))\n",
    "        return multiple_patches\n",
    "\n",
    "\n",
    "\n",
    "# patch shift layer\n",
    "# Note: order matters. First argument is patches, second has shape=[x_shift, y_shift]\n",
    "class patch_shift(layers.Layer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(patch_shift, self).__init__()\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        pass\n",
    "    \n",
    "    def call(self, inputs):    \n",
    "        # get dimensions of the patch\n",
    "        dims = tf.shape(inputs[0])\n",
    "\n",
    "        # update patch lenth\n",
    "        a = tf.concat((inputs[0], -2 * tf.ones(shape=(dims[0], dims[1], 299 - dims[2], 3), dtype=tf.float32)), axis=2)\n",
    "\n",
    "        # update patch height\n",
    "        b = tf.concat((a, -2 * tf.ones(shape=(dims[0], 299 - dims[1], 299, 3))), axis=1)\n",
    "\n",
    "        # shift the patch to the place needed\n",
    "        mapped_patches = tf.roll(b, shift = (inputs[1][0][0], inputs[1][0][1]), axis = (2, 1))\n",
    "\n",
    "        return mapped_patches\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# patch application layer\n",
    "# Note: order matters. First argument is images, second is patches\n",
    "class patch_applicator(layers.Layer):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(patch_applicator, self).__init__()\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        pass\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # prepare a mask for original images\n",
    "        img_mask = tf.math.abs(tf.math.add(tf.math.sign(tf.math.add(inputs[1], 2)), -1))\n",
    "        # crop the place for the pathch\n",
    "        cropped_images = tf.math.multiply(inputs[0], img_mask)\n",
    "\n",
    "        # prepare a mask for patches\n",
    "        patch_mask = tf.math.sign(tf.math.add(inputs[1], 2))\n",
    "\n",
    "        # crop patch from the field of -2-s\n",
    "        cropped_patch = tf.math.multiply(inputs[1], patch_mask)\n",
    "\n",
    "        # get images with patches\n",
    "        images_with_patches = cropped_images + cropped_patch\n",
    "        \n",
    "        return images_with_patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear previous session\n",
    "tf.keras.backend.clear_session() \n",
    "\n",
    "\n",
    "# initialize inputs\n",
    "input_image = tf.keras.layers.Input(shape=(299, 299, 3))\n",
    "input_shift = tf.keras.layers.Input(shape=(2,), dtype=tf.int32)\n",
    "\n",
    "\n",
    "# multiply patch\n",
    "patch_multiplier_layer = patch_multiplier(patch_size=size)\n",
    "patch_array = patch_multiplier_layer(input_image)\n",
    "\n",
    "\n",
    "# shift patch\n",
    "patch_shift_layer = patch_shift()\n",
    "shifted_patch_array = patch_shift_layer([patch_array, input_shift])\n",
    "\n",
    "\n",
    "# apply patch\n",
    "patch_applicator_layer = patch_applicator()\n",
    "adv_images = patch_applicator_layer([input_image, shifted_patch_array])\n",
    "\n",
    "\n",
    "# declare submodel for convenience\n",
    "image_processing_module = keras.models.Model(inputs=[input_image, input_shift], outputs=adv_images)\n",
    "\n",
    "\n",
    "# declare inception and set it parameters as non-trainable\n",
    "incv3 = tf.keras.applications.InceptionV3(weights=\"imagenet\")\n",
    "incv3.trainable=False\n",
    "\n",
    "\n",
    "# connect output of submodel to the input of inception\n",
    "out = incv3(image_processing_module.output)\n",
    "\n",
    "\n",
    "# declare main model\n",
    "adv_learning_model = keras.models.Model(inputs=[input_image, input_shift], outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "patch_multiplier (patch_multipl (None, 50, 50, 3)    7500        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "patch_shift (patch_shift)       (None, None, 299, 3) 0           patch_multiplier[0][0]           \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "patch_applicator (patch_applica (None, 299, 299, 3)  0           input_1[0][0]                    \n",
      "                                                                 patch_shift[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "inception_v3 (Model)            (None, 1000)         23851784    patch_applicator[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,859,284\n",
      "Trainable params: 7,500\n",
      "Non-trainable params: 23,851,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "adv_learning_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_1:0\", shape=(None, 299, 299, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# clear previous session\n",
    "tf.keras.backend.clear_session() \n",
    "\n",
    "shifted_patch_array = None\n",
    "\n",
    "# initialize inputs\n",
    "input_image = tf.keras.layers.Input(shape=(299, 299, 3))\n",
    "input_shift = tf.keras.layers.Input(shape=(2,), dtype=tf.int32)\n",
    "\n",
    "print(input_image)\n",
    "\n",
    "# multiply patch\n",
    "patch_multiplier_layer = patch_multiplier(patch_size=size)\n",
    "patch_array = patch_multiplier_layer(input_image)\n",
    "\n",
    "\n",
    "# shift patch\n",
    "patch_shift_layer = patch_shift()\n",
    "shifted_patch_array = patch_shift_layer([patch_array, input_shift])\n",
    "\n",
    "# apply patch\n",
    "patch_applicator_layer = patch_applicator()\n",
    "adv_images = patch_applicator_layer([input_image, shifted_patch_array])\n",
    "\n",
    "\n",
    "\n",
    "incv3 = tf.keras.applications.InceptionV3(weights=\"imagenet\")\n",
    "incv3.trainable=False\n",
    "x = incv3(adv_images)\n",
    "\n",
    "\n",
    "model1 = keras.models.Model(inputs=[input_image, input_shift], outputs=x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "patch_multiplier (patch_multipl (None, 50, 50, 3)    7500        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "patch_shift (patch_shift)       (None, None, 299, 3) 0           patch_multiplier[0][0]           \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "patch_applicator (patch_applica (None, 299, 299, 3)  0           input_1[0][0]                    \n",
      "                                                                 patch_shift[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "inception_v3 (Model)            (None, 1000)         23851784    patch_applicator[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 23,859,284\n",
      "Trainable params: 7,500\n",
      "Non-trainable params: 23,851,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_209AS",
   "language": "python",
   "name": "venv_209as"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
