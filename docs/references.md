---
layout: default
---
# References 
[1] Szegedy C. et al, "Going deeper with convolutions", technical report, 2014.

[2] Goodfellow I. et al, "Explaining and Harnessing Adversarial examples", ICLR, 2015.

[3] Kurakin A. et al, "Adversarial attacks in physical world", ICLR, 2017.

[4] Brown T. et al, "Adversarial Patch", CVPR, 2017.

[5] Chen S.-T. et al, "ShapeShifter: Robust Physical Adversarial Attack on Faster R-CNN Object Detector", Joint European Conference on Machine Learning and Knowledge Discovery in Databases, 2018.

[6] Eykholt K. et al, "Robust Physical-World attacks on Deep Learning Visual Recognition", CVPR, 2018.

[7] Pautov M. et al, "On adversarial patches: real-world attack opn ArcFace-100 face recognition system", 2019.

[8] Thys S. et al, "Fooling automated surveillance cameras: adversarial patches to attack person detection", 2019.

[9] Xu Kaidi et al, "Adversarial T-shirt! Evading Person Detectors in A Physical World", 2019

## Image Sources
[1] Wrinkles: https://netdna.coolthings.com/wp-content/uploads/2013/04/woolprince2.jpg

[2] Pandas from "Explaining and Harnessing Adversarial Examples": https://miro.medium.com/max/2000/1*PmCgcjO3sr3CPPaCpy5Fgw.png
